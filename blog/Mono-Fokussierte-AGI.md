# OpenAI's Deep Research und die Entstehung der "Mono-Fokussierten AGI"

AGI (Artificial General Intelligence) ist ein bemerkenswert problematischer Begriff \- überhyped und ohne präzise Definition. Dennoch zeichnet sich am Horizont eine faszinierende Entwicklung ab: Wir erleben die Entstehung dessen, was ich als "Mono-fokussierte AGI" bezeichne \- KI-Systeme, die in hochspezialisierten Bereichen menschliche Fähigkeiten nicht nur erreichen, sondern deutlich übertreffen. Diese Systeme sind zwar auf einzelne Domänen beschränkt, zeigen aber innerhalb ihrer Spezialisierung bemerkenswerte Anzeichen allgemeiner Intelligenz. Dabei ist es wichtig zu verstehen: Dieser Horizont liegt nicht in ferner Zukunft \- wir sind bereits mittendrin\!

Diese Entwicklung kommt nicht überraschend \- die Tech-Oligarchen prophezeien sie praktisch schon seit 2023\. Philip von AI Explained hat dazu auf seinem Patreon eine aufschlussreiche Dokumentation über die (rein männlichen\!) Tech-CEOs und die Entwicklung ihrer AI Labs veröffentlicht.[^1]

Leopold Aschenbrenner hat im Juni 2024 einen wegweisenden Essay verfasst: "SITUATIONAL AWARENESS: The Decade Ahead".[^2] Seine These: Bis 2025/26 werden KI-Systeme viele Hochschulabsolventen in ihren Fähigkeiten übertreffen, und bis 2027 werden sie menschliche Arbeitskräfte in vielen Bereichen ersetzen können. Sein Zitat "You can see the future first in San Francisco" steht dabei in bemerkenswertem Kontrast zu meinen eigenen Erfahrungen dort \- ich habe in keiner anderen Stadt so viele obdachlose Menschen gesehen. Ein Vorbote einer gespaltenen Zukunft?

Über Reasoning-Modelle und o3 habe ich bereits geschrieben.[^3] Die Skalierung mit Test-Time Compute und das Training von effektiven Prompting-Strategien wie "Let's think step by step" und Verification führt zu beeindruckenden Ergebnissen bei Benchmarks. Alles was "leicht verifizierbar" ist, kann mit Reinforcement Learning gelöst werden \- das betrifft alle Mathematik-, Coding- und Logikaufgaben, also überall dort, wo im Training eine eindeutig richtige Lösung festgestellt werden kann. Dabei zielt Reinforcement Learning nicht auf die Lösungen selbst ab, sondern auf die Lösungswege.[^4]

Im Schatten des Medienechos zu R1 von Deep Seek entwickelt sich eine andere, möglicherweise noch bedeutendere Technologie: OpenAI's Deep Research. Ethan Mollick beschreibt es treffend als "The End of Search, The Beginning of Research".[^5] Deep Research verkörpert perfekt das Konzept der "Mono-fokussierten AGI" \- ein System, das zwar auf wissenschaftliches Recherchieren beschränkt ist, aber in diesem Bereich außergewöhnliche Fähigkeiten zeigt.

Aus dieser Entwicklung lassen sich mehrere zentrale Schlüsse ziehen:

1. Die technologische Entwicklung verläuft deutlich schneller als allgemein angenommen  
2. Alle Wissensjobs, die durch das "Reinforcement Learning eines Reasoning-Modells" abgedeckt werden können, stehen vor tiefgreifenden Transformationen  
3. KI übernimmt nicht primär Routineaufgaben, sondern zunehmend komplexe intellektuelle Herausforderungen  
4. Europa muss jetzt handeln\! Nach über 60 Prompting-Workshops wird mir klar: Unsere Gesellschaft ist nicht ausreichend vorbereitet. Wir sollten dringend umfassende Kompetenzen aufbauen: Technologieverständnis, Prompting-Kenntnisse, Programmierfähigkeiten, Workflow-Management und Datenkompetenz, kombiniert mit kritischem, sozialem und ethischem Denken sowie fundiertem Fachwissen in spezifischen Domänen.

Warum ist Deep Research ein so prägnantes Beispiel für "Mono-fokussierte AGI"? Das System demonstriert eindrucksvoll, wie eine komplexe menschliche Aufgabe \- das Recherchieren und Zusammenfassen von Wissen, Information und Methoden \- innerhalb von 5-10 Minuten von einem o3-basierten Agentensystem übernommen werden kann. Zwar ist es ausschließlich auf die akademische Recherche spezialisiert, aber in diesem Bereich erreicht es ein Niveau, das bisherige Systeme deutlich übertrifft.

Meine Tests mit verschiedenen akademischen Aufgabenstellungen belegen diese außergewöhnliche Leistungsfähigkeit:

* Eine Deep Research-Ausarbeitung aus einem Exposé zu einer bereits gut strukturierten Masterarbeit: Der Bekannte war von der Qualität und dem Output beeindruckt  
* Masterarbeit aus dem Bereich der Ethik: Eine sehr fundierte Ausarbeitung eines Teilbereichs, speziell zur Recherche empirischer Daten für eine Argumentation  
* Ausarbeitung eines Reflexionspapiers im pädagogischen Bereich: Das Ergebnis hätte man ohne Änderungen einreichen können und hätte eine Bestnote verdient. Das Fazit war aus meiner Perspektive als ehemaliger Lehramtsstudent sehr überzeugend \- auch wenn es natürlich keine echte persönliche Reflexion darstellt. Die Qualität wurde von einer erfahrenen Pädagogin bestätigt.  
* Ein wissenschaftliches Review zu einer digitalen Edition, konkret zu meiner eigenen Edition. Dabei wurde in der Analyse der Forschungsdaten sogar die Nachnutzung durch Kollegen entdeckt \- etwas, das mir selbst nicht bekannt war: [https://docs.google.com/document/d/1H1cKTqupQ2uK60bkEaMW1mEiPwaa7OanueNPxTS5ItY](https://docs.google.com/document/d/1H1cKTqupQ2uK60bkEaMW1mEiPwaa7OanueNPxTS5ItY/edit?tab=t.0#heading=h.mabk22my8kty)  
* Eine interessante Limitation: Die Suche nach Urkunden mit Abbildungen von Bienenkörben in der ottonischen Zeit in vorgegebenen Archiv-Informationsportalen. Diese Aufgabe erwies sich als zu komplex, da sie Datenbankschnittstellen und Bilderkennungsfähigkeiten erfordert. Dennoch lieferte das System wertvolle alternative Quellen, wie etwa eine thematisch passende Dissertation: [https://docs.google.com/document/d/1NTp93dBhIdfMtq-cfuOozhtn5KF84eDjecbjDA0hUX8](https://docs.google.com/document/d/1NTp93dBhIdfMtq-cfuOozhtn5KF84eDjecbjDA0hUX8/edit?usp=sharing)

Ist das ein Hype? Zweifellos. Ist es gleichzeitig eine fundamentale Realität? Absolut\!

Ein KI-System hat in einer spezifischen Aufgabe eine deutlich bessere Performance erreicht als mit anderen verfügbaren Systemen möglich ist. Perplexity ist zwar beeindruckend, kommt aber nicht an die Leistung von Deep Research heran. Diese Entwicklung deutet darauf hin, dass "Mono-fokussierte AGI"-Systeme in naher Zukunft weitere Bereiche transformieren werden. Es spricht nichts dagegen, dass ähnliche Systeme für "Deep Coding"[^6] entwickelt werden könnten, wo o3- (oder o4-) basierte Agents über längere Zeit arbeiten und fertig getestete Software produzieren.

Ein entscheidender Faktor für den erfolgreichen Einsatz dieser Systeme ist präzises Prompting: Beim Review waren die vorgegebenen Kriterien essentiell. Ich habe bei allen Abschlussarbeiten die Aufgabenstellungen sorgfältig mit Claude 3.5 Sonnet vorbereitet \- präzise und explizit formuliert. Die Details zum optimalen Prompting eines Reasoning-Modells sollten allerdings Thema eines späteren Blogs sein (wobei ich zögere, diese Information zu teilen, da ich damit möglicherweise meinen eigenen Job gefährde).

*Christopher Pollin \- DH Craft*

[^1]: The One Machine to Rule Them All \- Origin Stories. Mini-Documentary on How the Founding Vision of Each AGI Lab Went Awry. [https://www.patreon.com/posts/121940490](https://www.patreon.com/posts/121940490). Paid Content.

[^2]: Leopold Aschenbrenner. SITUATIONAL AWARENESS: The Decade Ahead. Juni 2024\. [https://situational-awareness.ai](https://situational-awareness.ai)

[^3]: [https://dhcraft.org/excellence/blog/New-Year-New-AI-IdeaLab-25](https://dhcraft.org/excellence/blog/New-Year-New-AI-IdeaLab-25)

[^4]: AI Explained. AGI: (gets close), Humans: 'Who Gets to Own it?'. [https://youtu.be/oUtbRMatq7s?si=afotrzgSisbw6Uuy](https://youtu.be/oUtbRMatq7s?si=afotrzgSisbw6Uuy)

[^5]: Ethan Mollick. The End of Search, The Beginning of Research. [https://www.oneusefulthing.org/p/the-end-of-search-the-beginning-of](https://www.oneusefulthing.org/p/the-end-of-search-the-beginning-of)

[^6]: OpenAI CEO: "Super Human Coders By End of 2025". [https://youtu.be/48-Cg4i-8oI?si=3HE5EV6LNUbEDWAk](https://youtu.be/48-Cg4i-8oI?si=3HE5EV6LNUbEDWAk)
